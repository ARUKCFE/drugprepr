---
title: "Using the new drugprepr user interface"
author: David Selby
date: October 2021
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using the new drugprepr user interface}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This is a development document and may be removed or hidden when the package is
released.

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(drugprepr)
example_therapy
```

## Universe

Recall the original user interface is implemented as follows.

```{r}
run.drugPREP
```

That is, we perform the following steps in series:

1. Implausible total quantity
2. Missing total quantity
3. Implausible daily dose
4. Missing daily dose
5. Clean duration
6. Select stop date type
7. Missing stop date (i.e. impute missing durations)
8. Multiple prescriptions with same start date
9. Overlapping prescriptions
10. Gaps between prescriptions

With the new user interface:

```{r}
plausible_values <- data.frame(
  prodcode = c('a', 'b', 'c'),
  min_qty = 0,
  max_qty = c(50, 100, 200),
  min_ndd = 0,
  max_ndd = c(10, 20, 30)
)
```

```{r pipeline}
library(dplyr)
example_therapy %>%
  # Merge with data about plausible doses and total quantities for each drug.
  left_join(plausible_values, by = 'prodcode') %>%
  # 1.  Delete implausible total quantity.
  impute_qty(method = 'replace', where = function(q) q < .$min_qty | q > .$max_qty) %>%
  # 2.  Impute missing total quantity.
  impute_qty(method = 'median', where = is.na, group = 'pracid') %>%
  # 3.  Delete implausible daily doses.
  impute_ndd(method = 'replace', where = function(d) d < .$min_ndd | d > .$max_ndd) %>%
  # 4.
  impute_ndd(method = 'mean', where = is.na, group = 'patid') %>%
  # Remove auxiliary range variables.
  select(-starts_with('max_'), -starts_with('min_')) %>%
  # Compute prescription duration from ndd and total qty.
  mutate(duration = qty / ndd) %>%
  # 5.  Clean overly-long durations
  clean_duration(max_months = 6, 'truncate') %>%
  # 7.  Select stop date type (this is a weird one because it could make all previous steps redundant?)
  mutate(stop_date = start_date + duration) %>% # vs numdays vs dose_duration(?)
  # 8.  Clashing stop date (maybe this step should go before the previous one?)
  impute_duration(method = 'mean', where = function(x) length(x) > 1, group = c('patid', 'start_date')) %>%
  distinct(patid, prodcode, start_date, .keep_all = TRUE) %>% # this is the only time up to this point that nrow varies
  # 9.  Overlapping prescription - first split into overlapping and non-overlapping intervals
  isolate_overlaps() %>%
  # then disambiguate (or shift overlaps)
  distinct(patid, prodcode, start_date, .keep_all = TRUE) %>%
  # 10. Gaps between prescriptions
  close_small_gaps()
```
OK, so that handles one run of drug preparation.

```{r}
library(ggplot2)
ggplot(transform(example_therapy, stop_date = start_date + qty / ndd)) +
  geom_errorbarh(aes(xmin = start_date, xmax = stop_date, y = prodcode)) +
  facet_wrap(~ patid, labeller = label_both)
```

## Overlaps

Generate some overlapping data:

```{r overlap-test, fig.width = 5, fig.height = 3}
set.seed(1)
overlap_therapy <- data.frame(
  rowid = 1:20,
  patid = 1:2,
  prodcode = 'a',
  start_date = Sys.Date() + c(round(rexp(19, 1/7)), -20),
  qty = rpois(20, 64),
  ndd = sample(seq(.5, 12, by = .5), 20, replace = TRUE),
  stringsAsFactors = FALSE
)

ggplot(transform(overlap_therapy, stop_date = start_date + qty / ndd)) +
  aes(y = as.factor(rowid)) +
  geom_errorbarh(aes(xmin = start_date, xmax = stop_date)) +
  facet_wrap(~ patid, labeller = label_both, scales = 'free_y') +
  ylab(NULL)
```

Find the overlaps using `lubridate`.

This is based on code in `intervalaverageL::isolateoverlaps`.

```{r isolate overlaps, fig.width=5, fig.height = 3}
# library(lubridate)
library(tidyr)
# Divide timeline into intervals (including gaps!)
overlap_therapy %>%
  mutate(stop_date = start_date + qty / ndd) %>%
  pivot_longer(c(start_date, stop_date)) %>% # melt
  arrange(patid, prodcode, value, name) %>% # setorderv
  group_by(patid, prodcode) %>%
  transmute(rowid, value, # shift
            is_end_var = name == 'stop_date',
            end_next_var = lead(is_end_var),
            value_next_var = lead(value)) %>%
  filter(!is.na(end_next_var)) %>%
  transmute(rowid,
            start_date = if_else(!is_end_var, value, value + 1),  # temp (l1)
            stop_date = if_else(!end_next_var, value_next_var - 1, value_next_var)) %>%
  filter(stop_date >= start_date) -> temp # temp (l2)

x <- overlap_therapy %>%
  mutate(stop_date = start_date + qty / ndd)

# should yield dataset where intervals exactly overlap or else mutually don't overlap:
# (essentially: takes 'temp' and then deletes intervals that correspond to gaps)
out <- sqldf::sqldf(
    'SELECT x.patid, x.prodcode, x.rowid,
            y.rowid yrowid, y.start_date, y.stop_date
     FROM x
     JOIN temp y
     ON (x.start_date BETWEEN y.start_date AND y.stop_date) OR
        (x.stop_date BETWEEN y.start_date AND y.stop_date) OR
        (x.start_date < y.start_date AND x.stop_date > y.stop_date) OR
        (x.start_date > y.start_date AND x.stop_date < y.stop_date)
     WHERE x.patid = y.patid AND x.prodcode = y.prodcode'
)

ggplot(out) +
  aes(y = as.factor(rowid)) +
  geom_errorbarh(aes(xmin = start_date, xmax = stop_date), position = 'dodge2') +
  facet_wrap(~ patid, labeller = label_both, scales = 'free_y') +
  ylab(NULL)

ggplot(out %>%
         mutate(new_id = forcats::fct_reorder(as.factor(row_number()), start_date)) %>%
         distinct(patid, prodcode, start_date, .keep_all = TRUE)) +
  # ^ this works because intervals either overlap completely or not at all,
  # so you it is enough to take one interval for each unique start date
  aes(y = new_id) +
  geom_errorbarh(aes(xmin = start_date, xmax = stop_date), position = 'dodge2') +
  facet_wrap(~ patid, labeller = label_both, scales = 'free_y') +
  ylab(NULL)
```

Now implemented as a function in the package:

```{r}
isolate_overlaps(x)
```

## Multiverse

How can we parametrise it for multiple sets of decisions?

With a tidy decision set, of course!

That is, we define a data frame containing vectors of values, functions and decision rules (one row per decision set) and pass it as input to a wrapper function that runs all of the above, and spits out a list of data frames of length equal to the number of rows in the decision table.

Then define a function that populates the various arguments according to these coded decision rules:

```{r}
out <- drug_prep(example_therapy, plausible_values)
```

Practically speaking, this might consume all available memory, so it might make sense to write each table to disk rather than store them all in one list in RAM.
However, perhaps we could give the user the option, depending on data size.


